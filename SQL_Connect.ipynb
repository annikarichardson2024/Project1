{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annikarichardson2024/Project1/blob/main/SQL_Connect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Find your data sources....saklia, csv of oscars and country API\n",
        "1.1 Make you new datqbase tables.\n",
        "2. Connect to the YOUR database aer6bk and make you tables..using the create table command. you can python to do\n",
        "3. Find your your data and extract and [push it to you new datatbases....SQL Select --> DF --> df.to_sql\n",
        "4. for csc same...load csv into your DF and then DF.to_sql\n",
        "5...API call for hte world...put back in the datafarame and to sql...\n",
        "\n",
        "last thing is to talk to your new database. select statement on aer6bk"
      ],
      "metadata": {
        "id": "wIhpB176SXnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMySQL\n",
        "!pip install mysql-connector-python\n",
        "!pip install sqlalchemy"
      ],
      "metadata": {
        "id": "aL3IXDT4Q5Yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3969ce-5178-4332-fae2-6dcadb086063"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMySQL\n",
            "  Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMySQL\n",
            "Successfully installed PyMySQL-1.1.0\n",
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.3.0-cp310-cp310-manylinux_2_17_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.3.0\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.29)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "host_name = \"datatbase.ds2002.org\"\n",
        "#host_ip = \"127.0.0.1\"\n",
        "port = \"3306\"\n",
        "\n",
        "user_id = \"aer6bk\"\n",
        "pwd = \"aer6bk!\"\n",
        "db_name = \"aer6bk\""
      ],
      "metadata": {
        "id": "SKoCull1Q1Un"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pymysql\n",
        "import warnings\n",
        "\n",
        "conn = pymysql.connect(host=host_name, user=user_id, password=pwd, database=db_name)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "try:\n",
        "    cursor.execute('SELECT * FROM actor;')\n",
        "\n",
        "    for row in cursor.fetchmany(size=10):\n",
        "        print(row)\n",
        "\n",
        "    cursor.close()\n",
        "\n",
        "except:\n",
        "    print (\"Error: unable to fetch data\")\n",
        "\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_krDDrfPSavY",
        "outputId": "6532c23d-9347-4afe-a8f0-d3d06dfd8694"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'PENELOPE', 'GUINESS', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(2, 'NICK', 'WAHLBERG', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(3, 'ED', 'CHASE', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(4, 'JENNIFER', 'DAVIS', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(5, 'JOHNNY', 'LOLLOBRIGIDA', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(6, 'BETTE', 'NICHOLSON', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(7, 'GRACE', 'MOSTEL', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(8, 'MATTHEW', 'JOHANSSON', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(9, 'JOE', 'SWANK', datetime.datetime(2006, 2, 15, 4, 34, 33))\n",
            "(10, 'CHRISTIAN', 'GABLE', datetime.datetime(2006, 2, 15, 4, 34, 33))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD CSV\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/DS3001/linearRegression/main/data/Q1_clean.csv')\n",
        "df.loc[:,['Price','Neighbourhood '] ].groupby('Neighbourhood ').describe()"
      ],
      "metadata": {
        "id": "OoIbMAcBfyC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API CALL\n",
        "import os\n",
        "import json\n",
        "import pprint\n",
        "import requests\n",
        "import requests.exceptions\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_api_response(url, response_type):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        return \"An Http Error occurred: \" + repr(errh)\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        return \"An Error Connecting to the API occurred: \" + repr(errc)\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        return \"A Timeout Error occurred: \" + repr(errt)\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        return \"An Unknown Error occurred: \" + repr(err)\n",
        "\n",
        "    if response_type == 'json':\n",
        "        result = json.dumps(response.json(), sort_keys=True, indent=4)\n",
        "    elif response_type == 'dataframe':\n",
        "        result = pd.json_normalize(response.json())\n",
        "    else:\n",
        "        result = \"An unhandled error has occurred!\"\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "kCKKySImNAvK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://restcountries.com/v3.1/name/de\"\n",
        "response_type = ['json', 'dataframe']\n",
        "df = get_api_response(url, response_type[1])\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "df.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "49HXEHsfeAku",
        "outputId": "6bb1507a-2256-4a32-cd82-c3f9a903c12a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68, 361)\n",
            "Index(['tld', 'cca2', 'ccn3', 'cca3', 'cioc', 'independent', 'status',\n",
            "       'unMember', 'capital', 'altSpellings',\n",
            "       ...\n",
            "       'name.nativeName.tam.common', 'currencies.LKR.name',\n",
            "       'currencies.LKR.symbol', 'languages.sin', 'languages.tam',\n",
            "       'name.nativeName.rus.official', 'name.nativeName.rus.common',\n",
            "       'currencies.RUB.name', 'currencies.RUB.symbol', 'languages.rus'],\n",
            "      dtype='object', length=361)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 68 entries, 0 to 67\n",
            "Columns: 361 entries, tld to languages.rus\n",
            "dtypes: bool(3), float64(13), int64(1), object(344)\n",
            "memory usage: 190.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_string = get_api_response(url, response_type[0])\n",
        "print(json_string)"
      ],
      "metadata": {
        "id": "gKDeWO67fmtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}